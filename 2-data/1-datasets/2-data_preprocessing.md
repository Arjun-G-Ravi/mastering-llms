# Data preprocessing
- Common steps:
  - Cleaning: Remove duplicates, irrelevant content, and formatting issues.
  - Tokenization: Convert text into tokens using the model's tokenizer.
  - Normalization: Lowercasing, removing special characters, etc. -> Very dependent on use case, less so for modern LLMs.
  - Splitting: Divide data into training, validation, and test sets.